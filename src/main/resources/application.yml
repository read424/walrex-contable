quarkus:
  application:
    name: admon-catalogo
  http:
    body:
      uploads-directory: tmp/uploads
      merge-form-attributes: true
    limits:
      max-body-size: 10M
    port: 8089
    non-application-root-path: /q
    # Configuración de CORS
    #cors:
      #  ~: true  # Habilitar CORS para todas las rutas
      #origins: "*"  # Permitir todos los orígenes (puedes especificar URLs específicas)
      # Para producción, reemplaza "*" con tus dominios específicos:
      # origins: "http://localhost:3000,https://tu-dominio.com,https://app.tu-dominio.com"
      #methods: "GET,POST,PUT,DELETE,OPTIONS,PATCH"
      #headers: "accept,authorization,content-type,x-requested-with"
      #exposed-headers: "Content-Disposition"
      #access-control-max-age: 24H
    #access-control-allow-credentials: false  # Cambiar a true si usas cookies/autenticación
  # Deshabilitar Dev Services globalmente y para todas las extensiones
  devservices:
    enabled: false
  test:
    integration-test-profile: test
  # Datasource REACTIVE para la aplicación
  datasource:
    devservices:
      enabled: false
    db-kind: postgresql
    username: postgres
    password: 12345
    reactive:
      url: postgresql://127.0.0.1:5432/walrex_db
      max-size: 20
  swagger-ui:
    always-include: true
    path: /swagger-ui
  # Deshabilitar Dev Services específicamente para Redis
  redis:
    devservices:
      enabled: false
    hosts: redis://127.0.0.1:6379
    timeout: 10s
    max-pool-size: 20
    max-pool-waiting: 24
  cache:
    redis:
      expire-after-write: 30m
      prefix: "wx-admon"
  # OpenTelemetry - Distributed Tracing
  otel:
    enabled: true
    sdk:
      disabled: false
    service:
      name: admon-catalogo
    traces:
      sampler:
        arg: 1.0  # Capturar el 100% de las trazas (en dev)
    exporter:
      otlp:
        endpoint: http://localhost:4317
    propagators:
      - tracecontext
      - baggage
    resource:
      attributes:
        service.name: admon-catalogo
        service.version: 1.0.0-SNAPSHOT
        deployment.environment: dev

  micrometer:
    enabled: true
    registry-enabled-default: false
    export:
      prometheus:
        path: /q/metrics
    binder:
      # JVM Metrics
      jvm: true
      # System Metrics
      system: true
      # HTTP Server Metrics
      http-server:
        enabled: true
        max-uri-tags: 100
      # HTTP Client Metrics
      http-client:
        enabled: true
      # Vert.x Metrics (Event Loop)
      vertx:
        enabled: true
      # MP Metrics (MicroProfile)
      mp-metrics:
        enabled: true
    binder-enabled-default: true
  # Logging configuration moved to logback.xml
  log:
    level: INFO
    min-level: TRACE

  # SmallRye Fault Tolerance Metrics
  smallrye-fault-tolerance:

  # LangChain4j Configuration - Multiple Named Model Instances
  langchain4j:
    # Deshabilitar DevServices para usar providers externos
    devservices:
      enabled: false
    # Especificar provider para embedding model
    embedding-model:
      provider: ollama
    # Modelo "groq" usando OpenAI provider (Groq API)
    groq:
      chat-model:
        provider: openai
    # Modelo "ollama-local" usando Ollama provider
    ollama-local:
      chat-model:
        provider: ollama
    # Provider OpenAI - Configuración para modelo "groq"
    openai:
      groq:
        base-url: https://api.groq.com/openai/v1
        api-key: ${GROQ_API_KEY}
        timeout: 60s
        log-requests: false
        log-responses: false
        chat-model:
          model-name: llama-3.1-8b-instant
          temperature: 0.7
    # Provider Ollama local
    ollama:
      ollama-local:
        base-url: http://localhost:11434
        timeout: 60s
        log-requests: false
        log-responses: false
        chat-model:
          model-id: llama3.2
          temperature: 0.7
      # Embedding model sin nombre (default)
      base-url: http://localhost:11434
      timeout: 60s
      devservices:
        enabled: false
      embedding-model:
        model-id: mxbai-embed-large
        # mxbai genera embeddings de 1024 dimensiones

  # REST Client configuration for Binance P2P API
  rest-client:
    binance-p2p:
      url: https://p2p.binance.com
      scope: jakarta.enterprise.context.ApplicationScoped
      read-timeout: 30000
      connect-timeout: 10000
    # Azure Document Intelligence REST Client
    azure-doc-intel:
      url: https://mi-extractor-documentos.cognitiveservices.azure.com/
      scope: jakarta.enterprise.context.ApplicationScoped
      read-timeout: 60000
      connect-timeout: 10000

# Azure Document Intelligence Configuration
azure:
  doc:
    intel:
      key: ${AZURE_DOC_INTEL_KEY:your-azure-key-here}

# Qdrant Vector Database Configuration
quarkus:
  langchain4j:
    qdrant:
      host: localhost
      port: 6334
      api-key: ${QDRANT_API_KEY:}
      use-tls: false
      collection-name: accounting_accounts
      dimension: 1024  # mxbai-embed-large genera vectores de 1024 dimensiones
      distance: Cosine

# Embeddings Sync Configuration
embeddings:
  sync:
    enabled: true
    on-startup: true
    batch-size: 50